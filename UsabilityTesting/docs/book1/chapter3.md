## 分类

### 总结性评价和形成性评价

- **总结性评价**：检测成果
  - **性能测试法**
  - 发生在设计前和设计后
- **形成性评价**：中途收集，根据反馈改进
  - 在产品设计过程中反复使用

<span class="wavy">在评价可用性时，先确定目前的界面设计到底处于哪个阶段。</span>

另外还有一个原则必须牢记，那就是“**如果只做了总结性评价，那肯定是完全无效的投资**”。虽然知道在性能测试中目标达成率大约是50%，但却不知道为什么另外半数的用户未能达到目标。即使知道主观满意度很低但也无法得知究竟是哪部分的用户体验不好。

不做形成性评价，只做总结性评价，就和“什么也没学就来参加期末考试”一样，结果一定不好，而且从中也不会得到任何改善方案。总结性评价应该是在做了很多努力之后，为了更好的掌握成果而采取的评价方法。

### 分析法和实验法

分析法也被称为**专家评审( Expert review)**，是一种让产品可用性工，程师及用户界面设计师等专家基于自身的专业知识和经验进行评价的一种方法。

**实验法**收集货真价实的用户使用数据，比较典型的是用户，测试法，但问卷调查等方法也属于此类。

也可以认为分析法和实验法的区别就是**用户是否参与其中**。

| 分析法             | 实验法                 |
| ------------------ | ---------------------- |
| 主观               | 客观                   |
| 评价结果是假设的   | 评价结果是“事实”       |
| 评价范围广         | 评价范围窄             |
| 设计初期也可评价   | 为了做评价，必须做原型 |
| 时间和费用消耗较小 |                        |



## 产品可用性检验

### 启发式评估法--启发式评估10原则（人机交互学博士 Jakob Nielsen 提出）

1. **系统状态的可视性 Visibility of system status **：指系统必须在一定时间内做出适当反馈，必须把现在正在执行的内容通知给用户
2. **系统和现实的协调 Match between system and the real word **：系统不应该使用指向系统的语言，必须**使用用户很熟悉的词汇、句子和信息展现方式**来和用户对话。必须遵循现实中用户的习惯，用自然且符合逻辑的顺序来把系统信息反馈给用户。
3. **用户操纵与自由程度 User control and freedom**：指用户经常会因为误解功能的含义二做出错误的操作，为了让他们从这种状态中尽快解脱，必须有非常明确的“紧急出口”。**必须提供任何时候都能从当前状态跳出来的出口，保证能够及时取消或再运行执行过的操作。**
4. **一贯性和标准化 Consistency and standards**：不应该让用户出现不同的词语、状况、行为是否意味着相同的意思这样的疑问。一般应该遵循平台的惯例--相同的操作下得到相同的结果。
5. **防止错误 Error prevention**：能一开始就防止错误发生的设计要比适当的错误信息更重要。
   1. 这个规则要求相比完善错误发生后的应对方案，更应该做的是**预防出错**。另外，在执行会带来重大影响的操作前，应该先弹出确认对话框，让用户再次确认是否执行该操作。
6. **识别好过回忆 Recognition rather than recal**：要把对象、动作、选项等可视化，是用户无需回忆，一看就懂。
   1. **尽量不要让用户从当前对话切换到别的会话时还必须记住某些信息，应该让使用系统的说明可视化，且任何时候都能轻易被调用。**
7. **灵活性和效率 Flexibility and efficiency of use**：用户频繁使用的操作要能够单独调整
   1. 提供快捷键和定制化服务
8. **简洁美观的设计 Aesthetic and minimalist design**：在用户对话中，应该尽量不要包含不相关及几乎用不到的信息，给用户带来视觉上的负担或使他们产生混乱
9. **帮助用户认知、判断和修复错误 Help users recognize, diagnose, recover from erros**：用通俗的语句表示错误信息（而不是现实错误码），明确指出问题，并提出建设性解决方案
10. **帮助文档几用户手册 Help and documentation**：这个规则要求在设计无需查看用户手册也能使用的系统的基础上，还应该提供帮助文档和用户手册。帮助文档里应该配备目录和搜索功能，**用户手册应该尽量简洁**。
    * 配备FAQ页面
    * 不只是介绍功能，还应该配上使用的步骤
    * 除了文字，还需要配上示意图及界面截图
    * 用户的等级(初级--高级等)和目的(引进--应用等)不同，用户手册也不相同

### 其他类似原则

* **施耐德曼博士**的八项黄金法则:
* 力求一致性
* 允许频繁使用快捷键
* 提供明确的反馈
* 在对话中提供阶段性的成果反馈
* 使错误的处理简单化
* 允许可逆操作
* 用户应掌握控制权
* 减轻用户记忆负担
* **IBM的设计原则**
  * 简单:不可因过度追求功能而牺牲产品的易用性
  * 支持:让用户控制系统,并积极协助
  * 熟悉:基于用户已知内容做设计
  * 直观:对象及操作要做到直观、易懂
  * 安心:能够预测处理的结果,且操作可回退
  * 满意:可以在使用过程中感觉到进步和成就
  * 可用:总是做到所有对象可用
  * 安全:尽量不让用户在使用过程中遇到麻烦
  * 灵活:提供可替换的对话途径
  * 个性定制:提供用户定制功能
  * 相似:通过使用优秀的视觉设计使对象看上去和实物一样
* **ISO 9241 Part-10:对话原则**
  * 适宜操作
  * 自动说明
  * 可控
  * 迎合用户期待
  * 容错
  * 适宜个性化
  * 适宜学习

### 启发式评估法实施步骤

1. **招募评价人员**：尼尔森认为需要5人，至少需要3人才能得到稳妥的结果
   1. 能够胜任评价启发式评估职位的人，一般是**产品可用性工程师**和**用户界面设计师**。产品可用性工程师可以从最贴近用户的视角出发来评价产品，而用户界面设计师可以从实现技术的角度来进行评价。比如，评价网站时，如果请到**网站设计师**的话，连最详细的HTML和 Script代码的编码也可以得到评价。
   2. 但是，**界面的设计师本人是不适合评价该界面的**。一方面是因为设计师本人不可能客观评价自己倾注了心血实现的产品。另一方面，即使做到了客观理智的评价，如果发现了问题，也会马上对产品进行修改，而不是反馈。在需要设计师进行评价时，最好还是请公司内其他设计团队的成员来做比较合适
2. **制定评价计划**
   1. 与用户测试等实验方法相比，启发式评估法可以评价界面中的大部分内容。尽管如此，评价产品的所有功能或者大型网站的整体内容还是比较困难的。**启发式评估法的优点之一就是不会耗费太多的时间和精力，但如果过度追求完美，就会使启发式评估法变得一无是处**。因此，<u>通常需要事先定好要评价界面的哪些部分</u>。
   2. 另外，**也要定好是依据哪个原则进行评价**。当然，鼻祖肯定是尼尔森的启发式评估十原则了，但使用“施耐德曼博土的黄金8法则”和“ISO9241:对话原则”在实际业务应用上也没有问题。可如果每个评价人员都是根据自身喜好选择评价法则，评价的基准就不一致。因此，**需要事先商定到底使用哪种设计原则来实施评价**。甚至也可以根据不同的评价目的，追加可访问性的相关指导手册。
   3. 尽管大家希望评价尽可能多的界面，但是**不可以为每位评价人员分配不同的评价部分**。如果评价部分不同，招募评价人员这件事就失去意义了为了提高评价的准确性，每个界面都应该从不同视角进行评价。
3. **实施评价**
   1. 启发式评估法并不是协商性质的评价方法，评价人员都是单独进行评价的，而原则上**禁止评价人员互相讨论**。启发式评估法的基准虽然是事先统一的，但是实施方法会根据评价人员的经验和技能稍有出入，一旦经过协商，这种特色就很难发挥出来了。**而且，一般的评价人员都会受到“有权威”的评价人员的影响，这就会丧失从多个视角进行评价的机会**。
   2. 具体的评价方法由评价人员自己决定。以网站为例，既可以从首页开始，按层次依序访问，也可以假定几个任务，然后在执行任务的过程中发现问题。另外，也有在输入项里输入一些异常值，或者改变使用环境(界面分辨率、网络速度、不同的浏览器等)等方法。
   3. **尼尔森博士推荐对界面进行两次评价**。第一次检査界面的流程是否正常，第二次详细检查各界面是否存在问题。
   4. 如上所述，用各种方式评价界面，同时把发现的问题整理成列表。问题列表里记录了能够定位问题发生位置的信息(界面名称或者界面编号)、具体的问题内容以及评价的基准等信息。
   5. 然而，启发式评估不应花费太多时间，因为设计团队急于知晓评价结果。一般来说，2~3天内即可完成单独的评价。就我个人的经验而言，对于网站一个小时评价一个页面，对于手机一个小时评价一个任务的话，大致就可以在预定时间内完成评价。
4. **召开评价人员会议**
   1. 当所有评价人员都完成了各自的评价后，要集中开个会。评价人员的会议一般需要半天时间(3~4小时)，因此在制定评价计划时，就应该确保在评价人员各自评价结束后的第二天或第三天召开会议的时间。
   2. 首先请评价人员代表汇报评价结果，其他评价人员一边听报告，一边随时就自己是否也发现了相同的问题，或发现了其他问题等发言。以网站为例，从首页开始，按层次依序往下对页面进行评价的方式比较常见。手机或其他家电一般都直接评价整个任务。
   3. 评价人员会议并不只是口头阐述，在会场上使用投影仪等设备把界面显示出来会更有效果和效率。
   4. 另外，虽然可以自由提问，但一般不会出现否定其他评价人员的情况。因为每位评价人员都是专家，而且都是以明确的基准进行评价的，所以得出的评价结果基本不会有问题(但是，这种问题在实际操作中是否真的会发生那就是另一个话题了。因为基于分析法得出的评价结果，都只是假设而已)
   5. 再者，召开评价人员会议的目的并不是为了统计到底有多少人指出了同一问题。经常会出现三人中只有一人发现了某界面中存在的严重的问题，另一个界面的严重问题则由另一个评价人员发现的情况。
   6. 启发式评估法的一个优点就是，通过“单独评价→评价人员之间的讨论”两层过滤方式，**可以发现单独一人不能发现的跨度较大的问题**。
5. **总结评价结果**
   1. 启发式评估法的成果就是“产品可用性问题列表”。但如果只单单给出列表，团队的其他成员理解起来会很困难，因此最好配上界面截图、界面流程图等形成简单的报告。另外，不能只看报告，应该进行集体讨论，当场商议问题的解决对策，这才是最有效率的做法。

### 启发性评估法的局限性

1. **查出的问题过多**，出现吹毛求疵的情况。
2. **实施成本**

因为各种各样的制约因素导致不能进行正规的启发式评估，而改为简易的审查时，请务必留意以下几点内容。

* 不以个人偏好，而应**以理论为依据**进行评价。可以不拘泥于启发式评估原则，但必须明确评价遵照的依据
* 评价的目的不是单纯的挑错，更应该**给出一些建议**。
* 设计师和检验人员平时应该充分沟通·当出现意见不一致时，与其把时间浪费在争论上，不如**使用实验的方法**得出正确的结论



### 认知过程走查法

启发式评估法是基于用户界面设计原理原则(启发)的一种检验方法。另外还存在一种基于人类的认知模式进行检验的方法—**认知过程走查法( Cognitive Walkthrough )** 。

所谓走查是指戏剧排练时不穿戏服、不使用舞台设备，只是拿着剧本排练。对用户界面的走查也是根据剧本(界面流程图)进行分析的。此时，我们会基于用户认知模型之一的**探索学习**理论寻找问题。

探索学习是指事先不阅读用户手册，也不接受培训，在使用的过程中学习使用方法。比如，大人在使用自动贩卖机和ATM时，一般都是“探索学习”。另外，在换新手机后，大多数用户也是通过“探索学习”来掌握新手机的使用方法的。

**探索学习四个步骤**:

1. **设定目标**:设定用户要达成什么目的(即任务或子任务
2. 探索:用户在用户界面里探索究竟该做什么操作。
3. **选择**:用户为了达到目的，选择他认为最合适的操作。
4. 评价:用户分析操作后系统的反馈，判断任务是否正常进行。

用户通过反复探索、选择、评价达成目的。如果目的是子任务，通过反复进行上述1~4的步骤来达成最终的任务。

**准备过程**：

1. **定义任务**
2. 确定执行任务的**操作步骤**和**界面**，一般来说做成一份界面流程图

**分析步骤**：

1. 用户是否知道自己要做什么？
2. 用户在探索用户界面的过程中是否注意到操作方法？
3. 用户是否把自己的目的和正确的操作方法关联到一起了？
4. 用户能否从系统的反馈中判断出任务是否在顺利进行？



## 用户测试

### 方法1：发声思考法 Think Aloud Method

发声思考法的一大特点就是让用户一边说出心里想的内容一边操作。在操作过程中，用户如果能够说出“现在我是这样想的……”“我觉得下面应该这样操作……”“我觉得这样做比较好是因为……”等话，我们也就能够把握用户关注的是界面的哪个部分、他是怎么想的、又采取了怎样的操作等信息。

使用了发声思考法的用户测试，并不局限于发现用户“操作失败了”“在操作过程中陷入了不知所措的困境”或者“非常不满意”等表象，而是一种能够弄清楚为什么会导致上述结果的非常有效的评估方法。

**观察重点**：

1. 首先观察用户**是否独立完成了任务**。若用户未能做到独立完成，可以认为该界面存在有效性问题。讲得严重点，这个界面根本不能用属于非常严重的可用性问题。
2. 若用户能够独立完成任务，那么接下来需要关注的就是用户在达到目的的过程中，**是否做了无效操作或遇到了不知所措的情况**。如果需要用户反复考虑使用方法，或者做了很多无效操作，那么这个界面就存在效率问题
3. 即使用户能够按照自己的方法独立完成任务，还有一点需要注意，那就是用户**是否有不满的情绪**。让用户用得不舒服的界面，可以认为存在满意度的问题。用户可能在执行过程中直接表达出不满，也可能从表情和态度上表现出不满。



### 方法2：回顾法 Retrospective Method

发声思考法是让用户一边发言一边操作的方法，还有一种是让用户在完成操作后回答问题的方法，我们称之为回顾法( Retrospective Method)。

回顾法中无需用户做特殊的操作，因此可以在比较自然的状态下实施。而且，对用户的提问也是在操作完成后进行，因此不必担心提出的问题会给用户一些操作上的提示。正因如此，经验尚浅的采访人员也可以轻松实施回顾法用户测试。

**缺点：**

1. 很难回顾复杂的状况
2. 用户经常在事后给自己的行为找借口
3. 回顾法非常耗时

### 方法3：性能测试 Performance Measurement

性能测试主要对产品可用性三要素(**有效性、效率、满意度**)的相关数据进行定量测试有效性可以用任务完成率来表示。

“有几成的用户**可以独立完成任务**”是界面检验里**最重要的一个性能指标**。这里的任务完成是指用户正确地完成了任务。比如，虽然在某服装网站上成功下单了，但如果大小搞错了就不能说完成了任务。或者用户不知道自己是否成功下单，这也不能说是完成了任务。

**效率**可以用任务完成时间来表示。一般来说，界面是为了让用户完成任务而设计的，因此能够在最短时间内让用户完成任务的界面才是优秀的界面。所以，需要检测用户完成任务花费的时间。但是，如果不加任何限制，用户可能花了一个小时只执行了一个简单的任务。因此，最好限制每个任务的时间，在限定时间内未能完成任务，就被当作任务未完成。另外除了任务完成时间，有时也需要统计操作步骤数及鼠标点击数等数据。

**满意度**可以用主观评价来表示。任务完成后，可以就“难易程度”“好感”“是否有再次使用的意向”等问题向用户提问，并设置5~10个等级让用户选择。国外开发了很多类似QUIS、SUMI、 WAMMI等的问题模板，不过绝大多数还没有中文版。而且很多都要收费，并且需要申请使用许可因此，通常我们都是在之前的满意程度调查问卷的基础上稍加修改后，用来检测满意度的。

**适用场景**：

1. 属于总结性评价，原则上会安排在项目前后实施
2. 只要还未明确定量数据的必要性，就不应该实施性能测试



## 用户测试的基础理论

### 产品可用性的理论基础

**用户测试是以反证为目的的测试。**

想要用事实来证明产品可用性是一件非常困难的事情。那么，究竞需要多少人来完成哪些种类的任务才能证明这个用户界面具备了可用性呢?以我现在用的手机为例，主菜单里一共有115项功能。若想在开发过程中评价所有的功能，无论从时间上还是费用上，都是不可能的。

因此，**首先假设该用户界面具备可用性**。当然，我们也不是凭空来做假设，若是基于背景调查法和启发式评估法设计出来的界面，目前我们就可以假设它具备可用性，**那么在理论上，用户应该可以使用该界面有效高效且心情愉悦地完成任务**。为了证明这个假设，就需要让用户实际操作来验证一下(挑选其中的主要功能)在这个过程中，可以使用发声思考法等方法进行详细分析。如果发现了违反有效性、效率和满意度的问题，那就是该假设的“反证”。此时，该用户界面具备可用性的假设不成立。我们也没有必要因为假设被推翻而觉得沮丧，因为用户测试本来就是种积极寻找反证的过程，发现问题是理所应当的。而且，使用了发声思考法的测试不仅可以发现问题，还可以同时发现该问题产生的原因，因此设计团队马上就可以开始研究针对这些问题的解决方案。随着问题的解决，该假设就又成立了。

另一方面，如果无论怎样分析都没有发现问题，评价人员也就不能举出反证。当然，你可以找更多的用户实施更多的任务，这样一定可以发现问题，但是永远会有新问题也永远在改善，这个循环是不会停止的。因此如果没找到反证，我们就认为假设成立，即该用户界面具备产品可用性。

### 用户测试的参与人数

$N(1-(1-L)^n)$

- N: 设计上存在的产品可用性问题的数量(因为是潜在的问题数量，所以这里只是一个假设的数值)
- L:一人参加测试发现的问题数量占总体问题数量的比例(尼尔森博士提出的经验值是0.31)
- n:参加测试的用户人数

<div class="frame">
<h4>无须知彼</h4>

假设这三个界面中,C是本公司产品,A和B是竞争对手的产品,那么C中发现的30个问题当然需要进一步进行研究和改善,但A和B中发现的问题却没有任何利用价值。相信不会有人把调查报告寄给竞争对手吧。

如果是营业部或者市场部的工作人员,一定会时刻关注竞争对手的动向。但在界面设计中,品质的标准不是由竞争对手而是用户决定的。以用户为中心的设计理念,并不是与竞争对手比较优劣,而是完全满足所有的用户需求。

正因如此,测试竞争对手的产品没有任何价值。应该把浪费在测试竞争对手产品上的测试经费,运用到本公司正在设计的界面上来。如果有测试3种界面的预算,就应该对自己的界面进行3次测试。

兵法讲“知己知彼,方能百战不殆",但在界面设计领域,具有讽刺意味的是,从你开始分析竞争对手的产品起,就决定了你今后的败局。
</div>



## 用户测试的实践基础

### 时间与费用

用户测试的日程安排一般在**4个星期**左右。

* **测试准备**：
  * 招募:约两个星期
  * 测试设计:约一个星期(※测试设计与招募同步进行)
* 实际操作: 2~3天
* **分析和报告**: 1~2周

*在日本，使用正规的实验室对10个人做1个半小时的测试，且全权委托调查公司来操作，大约需要300万日元(约18万人民币)。*





